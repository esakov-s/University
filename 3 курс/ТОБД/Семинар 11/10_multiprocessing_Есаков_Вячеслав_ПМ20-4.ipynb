{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параллельные вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Параллельные вычисления\"\n",
    "* https://docs.python.org/3/library/multiprocessing.html\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool\n",
    "    * https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "* https://numpy.org/doc/stable/reference/generated/numpy.array_split.html\n",
    "* https://nalepae.github.io/pandarallel/\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_windows.ipynb\n",
    "    * https://github.com/nalepae/pandarallel/blob/master/docs/examples_mac_linux.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Downloading pandarallel-1.6.3.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dill>=0.3.1\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     -------------------------------------- 110.5/110.5 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1 in c:\\python\\envs\\python_new\\lib\\site-packages (from pandarallel) (1.5.0)\n",
      "Requirement already satisfied: psutil in c:\\python\\envs\\python_new\\lib\\site-packages (from pandarallel) (5.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python\\envs\\python_new\\lib\\site-packages (from pandas>=1->pandarallel) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\python\\envs\\python_new\\lib\\site-packages (from pandas>=1->pandarallel) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python\\envs\\python_new\\lib\\site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\envs\\python_new\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py): started\n",
      "  Building wheel for pandarallel (setup.py): finished with status 'done'\n",
      "  Created wheel for pandarallel: filename=pandarallel-1.6.3-py3-none-any.whl size=16448 sha256=20d136e499096f4d33ff8787d71afe644c3159459ba4541c9ef3726c38fbf395\n",
      "  Stored in directory: c:\\users\\вячеслав\\appdata\\local\\pip\\cache\\wheels\\16\\f5\\91\\d7efa7c4911ae1cf1aff825f902382eb69a1855f9987a7d17c\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.6 pandarallel-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Посчитайте, сколько раз встречается буква \"a\" в файлах [\"xaa\", \"xab\", \"xac\", \"xad\"]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "files = [f\"{name}.txt\" for name in [\"xaa\", \"xab\", \"xac\", \"xad\"]]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_a(file):\n",
    "    with open(file) as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xaa.txt 2599627\n",
      "xab.txt 2605911\n",
      "xac.txt 2599868\n",
      "xad.txt 1460452\n",
      "CPU times: total: 7.28 s\n",
      "Wall time: 7.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2599627, 2605911, 2599868, 1460452]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "[count_a(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing count_a.py\n"
     ]
    }
   ],
   "source": [
    "%%file count_a.py\n",
    "from collections import Counter\n",
    "\n",
    "def count_a(file):\n",
    "    with open(file) as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_a import count_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2599627, 2605911, 2599868, 1460452]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    res = pool.map(count_a, files)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting count_a_q.py\n"
     ]
    }
   ],
   "source": [
    "%%file count_a_q.py\n",
    "from collections import Counter\n",
    "\n",
    "def count_a_q(file, queue):\n",
    "    with open(file) as fp:\n",
    "        text = fp.read().lower()\n",
    "    res = Counter(text)[\"a\"]\n",
    "    print(file, res)\n",
    "    queue.put(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_a_q import count_a_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.81 s\n",
      "Wall time: 2.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1460452, 2599868, 2599627, 2605911]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ps = []\n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "for f in files:\n",
    "    p = multiprocessing.Process(target=count_a_q, args=(f, queue))\n",
    "    ps.append(p)\n",
    "    p.start()\n",
    "\n",
    "rs = []\n",
    "while len(rs) < 4:\n",
    "    if not queue.empty():\n",
    "        rs.append(queue.get())\n",
    "    \n",
    "for p in ps:\n",
    "    p.join()\n",
    "\n",
    "rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Выведите на экран слова из файла words_alpha, в которых есть две или более буквы \"e\" подряд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9252575"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "words = (\n",
    "    pd.read_csv(\"words_alpha.txt\", header=None)[0]\n",
    "    .dropna()\n",
    "    .sample(frac=25, replace=True)\n",
    ")\n",
    "\n",
    "words.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def f(s): \n",
    "    return bool(re.findall(r\"e{2,}\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting f.py\n"
     ]
    }
   ],
   "source": [
    "%%file f.py\n",
    "import re\n",
    "\n",
    "def f(s): \n",
    "    return bool(re.findall(r\"e{2,}\", s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from f import f\n",
    "\n",
    "from pandarallel import pandarallel \n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "180573"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "words[words.map(f)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\envs\\Python_new\\lib\\site-packages\\pandarallel\\data_types\\series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Python\\envs\\Python_new\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Python\\envs\\Python_new\\lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"C:\\Python\\envs\\Python_new\\lib\\site-packages\\pandarallel\\core.py\", line 158, in __call__\n    results = self.work_function(\n  File \"C:\\Python\\envs\\Python_new\\lib\\site-packages\\pandarallel\\data_types\\series.py\", line 52, in work\n    return data.map(\n  File \"C:\\Python\\envs\\Python_new\\lib\\site-packages\\pandas\\core\\series.py\", line 4542, in map\n    new_values = self._map_values(arg, na_action=na_action)\n  File \"C:\\Python\\envs\\Python_new\\lib\\site-packages\\pandas\\core\\base.py\", line 890, in _map_values\n    new_values = map_f(values, mapper)\n  File \"pandas\\_libs\\lib.pyx\", line 2919, in pandas._libs.lib.map_infer\n  File \"C:\\Users\\Вячеслав\\AppData\\Local\\Temp\\ipykernel_15016\\488026415.py\", line 4, in f\nNameError: name 're' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mC:\\Python\\envs\\Python_new\\lib\\site-packages\\pandarallel\\core.py:433\u001b[0m, in \u001b[0;36mparallelize_with_pipe.<locals>.closure\u001b[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mError:\n\u001b[0;32m    431\u001b[0m         progress_bars\u001b[38;5;241m.\u001b[39mset_error(worker_index)\n\u001b[1;32m--> 433\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mresults_promise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_type\u001b[38;5;241m.\u001b[39mreduce(results, reduce_extra)\n",
      "File \u001b[1;32mC:\\Python\\envs\\Python_new\\lib\\multiprocessing\\pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words[words.parallel_map(f)].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__При решении данных задач не подразумевается использования циклов или генераторов Python в ходе работы с пакетами `numpy` и `pandas`, если в задании не сказано обратного. Решения задач, в которых для обработки массивов `numpy` или структур `pandas` используются явные циклы (без согласования с преподавателем), могут быть признаны некорректными и не засчитаны.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. В каждой строке файла `tag_nsteps.csv` хранится информация о тэге рецепта и количестве шагов в этом рецепте в следующем виде:\n",
    "\n",
    "```\n",
    "tags,n_steps\n",
    "hungarian,2\n",
    "european,6\n",
    "occasion,4\n",
    "pumpkin,4\n",
    "................\n",
    "```\n",
    "\n",
    "Всего в исходном файле хранится чуть меньше, чем 71 млн, строк. Разбейте файл `tag_nsteps.csv` на несколько (например, 8) примерно одинаковых по объему файлов c названиями `tag_nsteps_*.csv`, где вместо символа `*` указан номер очередного файла. Каждый файл имеет структуру, аналогичную оригинальному файлу (включая заголовок).\n",
    "\n",
    "__Важно__: здесь и далее вы не можете загружать в память весь исходный файл сразу. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Напишите функцию, которая принимает на вход название файла, созданного в результате решения задачи 1, считает для каждого тэга сумму по столбцу `n_steps` и количество строк c этим тэгом, и возвращает результат в виде словаря. Ожидаемый вид итогового словаря:\n",
    "\n",
    "```\n",
    "{\n",
    "    '1-day-or-more': {'sum': 56616, 'count': 12752},\n",
    "    '15-minutes-or-less': {'sum': 195413, 'count': 38898},\n",
    "    '3-steps-or-less': {'sum': 187938, 'count': 39711},\n",
    "    ....\n",
    "}\n",
    "```\n",
    "\n",
    "Примените данную функцию к каждому файлу, полученному в задании 1, и соберите результат в виде списка словарей. Не используйте параллельных вычислений. \n",
    "\n",
    "Выведите на экран значение по ключу \"30-minutes-or-less\" для каждого из словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_sum_count_from_file(file: str) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Напишите функцию, которая объединяет результаты обработки отдельных файлов. Данная функция принимает на вход список словарей, каждый из которых является результатом вызова функции `get_tag_sum_count_from_file` для конкретного файла, и агрегирует эти словари. Не используйте параллельных вычислений.\n",
    "\n",
    "Процедура агрегации словарей имеет следующий вид:\n",
    "$$d_{agg}[k] = \\{sum: \\sum_{i=1}^{n}d_{i}[k][sum], count: \\sum_{i=1}^{n}d_{i}[k][count]\\}$$\n",
    "где $d_1, d_2, ..., d_n$- результат вызова функции `get_tag_sum_count_from_file` для конкретных файлов.\n",
    "\n",
    "Примените данную функцию к результату выполнения задания 2. Выведите на экран результат для тэга \"30-minutes-or-less\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_results(tag_sum_count_list: list) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Напишите функцию, которая считает среднее значение количества шагов для каждого тэга в словаре, имеющего вид, аналогичный словарям в задаче 2, и возвращает результат в виде словаря . Используйте решения задач 1-3, чтобы получить среднее значение количества шагов каждого тэга для всего датасета, имея результаты обработки частей датасета и результат их агрегации. Выведите на экран результат для тэга \"30-minutes-or-less\".\n",
    "\n",
    "Определите, за какое время задача решается для всего датасета. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_mean_n_steps(tag_sum_count: dict) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Повторите решение задачи 4, распараллелив вызовы функции `get_tag_sum_count_from_file` для различных файлов с помощью `multiprocessing.Pool`. Для обработки каждого файла создайте свой собственный процесс. Выведите на экран результат для тэга \"30-minutes-or-less\". Определите, за какое время задача решается для всех файлов. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Повторите решение задачи 4, распараллелив вычисления функции `get_tag_sum_count_from_file` для различных файлов с помощью `multiprocessing.Process`. Для обработки каждого файла создайте свой собственный процесс. Для обмена данными между процессами используйте `multiprocessing.Queue`.\n",
    "\n",
    "Выведите на экран результат для тэга \"30-minutes-or-less\". Определите, за какое время задача решается для всех файлов. При замере времени учитывайте время расчета статистики для каждого файла, агрегации результатов и, собственно, вычисления средного. Временем, затрачиваемым на процедуру разбиения исходного файла можно пренебречь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Исследуйте, как влияет количество запущенных одновременно процессов на скорость решения задачи. Узнайте количество ядер вашего процессора $K$. Повторите решение задачи 1, разбив исходный файл на $\\frac{K}{2}$, $K$ и $2K$ фрагментов. Для каждого из разбиений повторите решение задачи 5. Визуализируйте зависимость времени выполнения кода от количества файлов в разбиении. Сделайте вывод в виде текстового комментария."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напишите функцию `parallel_map`, которая принимает на вход серию `s` `pd.Series` и функцию одного аргумента `f` и поэлементно применяет эту функцию к серии, распараллелив вычисления при помощи пакета `multiprocessing`. Логика работы функции `parallel_map` должна включать следующие действия:\n",
    "* разбиение исходной серии на $K$ частей, где $K$ - количество ядер вашего процессора;\n",
    "* параллельное применение функции `f` к каждой части при помощи метода _серии_ `map` при помощи нескольких подпроцессов;\n",
    "* объединение результатов работы подпроцессов в одну серию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(s: pd.Series, f: callable) -> pd.Series:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Напишите функцию `f`, которая принимает на вход тэг и проверяет, удовлетворяет ли тэг следующему шаблону: `[любое число]-[любое слово]-or-less`. Возьмите любой фрагмент файла, полученный в задании 1, примените функцию `f` при помощи `parallel_map` к столбцу `tags` и посчитайте количество тэгов, подходящих под этот шаблон. Решите ту же задачу, воспользовавшись методом _серий_ `map`. Сравните время и результат выполнения двух решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(tag: str) -> bool:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Используя пакет `pandarallel`, примените функцию `f` из задания 9 к столбцу `tags` таблицы, с которой вы работали этом задании. Посчитайте количество тэгов, подходящих под описанный шаблон. Измерьте время выполнения кода. Выведите на экран полученный результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
