{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИМПОРТ БИБЛИОТЕК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pymorphy2\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn import neighbors, model_selection, ensemble\n",
    "from sklearn import model_selection, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОДКЛЮЧЕНИЕ К ЦХД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = '10.42.100.64'\n",
    "port = '5432'\n",
    "user = 'nikolay.kozhevnikov' # необходимо ввести собственный логин от учетной записи\n",
    "database = 'edw_prod'\n",
    "pwd = '%z22u5#K5F' #необходимо ввести собственный пароль от учетной записи\n",
    "\n",
    "str_con = 'postgresql://'+user+':'+pwd+'@'+host+':'+port+'/'+database\n",
    "connection = create_engine(str_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБУЧЕНИЕ МОДЕЛИ МАШИННОГО ОБУЧЕНИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СЧИТЫВАНИЕ ИСХОДНЫХ НАБОРОВ ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет для профильности услуг\n",
    "textcorpus_profile = pd.DataFrame() # создание пустого датафрейма\n",
    "#textcorpus_profile[['purchase_name', 'label']] = pd.read_excel('textcorpus_profile.xlsx')[['Наименование закупки', 'Класс']]\n",
    "textcorpus_profile = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_profile\", connection)\n",
    "\n",
    "# датасет для мобильной связи\n",
    "textcorpus_mobile = pd.DataFrame() # создание пустого датафрейма\n",
    "#textcorpus_mobile[['purchase_name', 'label']] = pd.read_excel('textcorpus_mobile.xlsx')[['Наименование закупки', 'Класс']]\n",
    "textcorpus_mobile = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_mobile\", connection)\n",
    "\n",
    "# датасет для каналов связи\n",
    "textcorpus_link = pd.DataFrame() # создание пустого датафрейма\n",
    "#textcorpus_link[['purchase_name', 'label']] = pd.read_excel('textcorpus_link.xlsx')[['Наименование закупки', 'Класс']] \n",
    "textcorpus_link = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_link\", connection)\n",
    "\n",
    "# датасет для интернета\n",
    "textcorpus_internet = pd.DataFrame() # создание пустого датафрейма\n",
    "#textcorpus_internet[['purchase_name', 'label']] = pd.read_excel('textcorpus_internet.xlsx')[['Наименование закупки', 'Класс']]\n",
    "textcorpus_internet = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_internet\", connection)\n",
    "\n",
    "# датасет для телефонии\n",
    "textcorpus_telephony = pd.DataFrame() # создание пустого датафрейма\n",
    "#textcorpus_telephony[['purchase_name', 'label']] = pd.read_excel('textcorpus_telephony.xlsx')[['Наименование закупки', 'Класс']]\n",
    "textcorpus_telephony = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_telephony\", connection)\n",
    "\n",
    "# датасет для поставки\n",
    "textcorpus_shipment = pd.DataFrame() # создание пустого датафрейма\n",
    "textcorpus_shipment = pd.read_sql(\"SELECT purchase_name, label FROM textcorpus_shipment\", connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОДГОТОВКА ПЕРЕМЕННЫХ ДЛЯ ПРЕДОБРАБОТКИ ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание списка символов для токенизации по словам\n",
    "words_separators = '[;,.,\\n,\\s,:,-,+,(,),=,/,«,»,@,\\d,!,?,\",1,2,3,4,5,6,7,8,9,0,*,_,”,“,-]' \n",
    "# создание списка мусорных слов\n",
    "stop_words = ['для', 'про', 'пао', 'или', 'без', 'через', 'при', 'под', 'над', 'перед']\n",
    "# создание морфологического анализатора для лемматизации слов\n",
    "pymorphy2 = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ФУНКЦИИ ДЛЯ ПРЕДОБРАБОТКИ ДАННЫХ И ИХ ПРИМЕНЕНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 59797,
     "status": "ok",
     "timestamp": 1602084161487,
     "user": {
      "displayName": "Piton Piton",
      "photoUrl": "",
      "userId": "17891623094940807329"
     },
     "user_tz": -180
    },
    "id": "y-85UFKrku-f"
   },
   "outputs": [],
   "source": [
    "# функция для приведения всех слов в нижний регистр\n",
    "# def lowercase(str):\n",
    "#     return str.lower()\n",
    "\n",
    "def lowercase(name):\n",
    "    return str(name).lower()\n",
    "\n",
    "# функция для токенизации по словам\n",
    "def tokenization(str):\n",
    "    words = [i for i in re.split(words_separators, str) if len(i) > 2 if i not in stop_words]\n",
    "    return words\n",
    "\n",
    "# функция для лемматизации слов\n",
    "def lemmatization(textcorpus_words):\n",
    "    for i in range(len(textcorpus_words.index)):\n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            textcorpus_words[i][j] = pymorphy2.parse(textcorpus_words[i][j])[0].normal_form\n",
    "    return textcorpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101909,
     "status": "ok",
     "timestamp": 1602084203606,
     "user": {
      "displayName": "Piton Piton",
      "photoUrl": "",
      "userId": "17891623094940807329"
     },
     "user_tz": -180
    },
    "id": "XhoFMYhRku-k",
    "outputId": "61caf85d-b5b3-447c-c454-c921dc84d4ff"
   },
   "outputs": [],
   "source": [
    "textcorpus_profile.purchase_name = textcorpus_profile.purchase_name.apply(lowercase)\n",
    "textcorpus_profile['words'] = textcorpus_profile.purchase_name.apply(tokenization)\n",
    "textcorpus_profile['lemma'] = lemmatization(textcorpus_profile['words'])\n",
    "\n",
    "textcorpus_mobile.purchase_name = textcorpus_mobile.purchase_name.apply(lowercase)\n",
    "textcorpus_mobile['words'] = textcorpus_mobile.purchase_name.apply(tokenization)\n",
    "textcorpus_mobile['lemma'] = lemmatization(textcorpus_mobile['words'])\n",
    "\n",
    "textcorpus_link.purchase_name = textcorpus_link.purchase_name.apply(lowercase)\n",
    "textcorpus_link['words'] = textcorpus_link.purchase_name.apply(tokenization)\n",
    "textcorpus_link['lemma'] = lemmatization(textcorpus_link['words'])\n",
    "\n",
    "textcorpus_internet.purchase_name = textcorpus_internet.purchase_name.apply(lowercase)\n",
    "textcorpus_internet['words'] = textcorpus_internet.purchase_name.apply(tokenization)\n",
    "textcorpus_internet['lemma'] = lemmatization(textcorpus_internet['words'])\n",
    "\n",
    "textcorpus_telephony.purchase_name = textcorpus_telephony.purchase_name.apply(lowercase)\n",
    "textcorpus_telephony['words'] = textcorpus_telephony.purchase_name.apply(tokenization)\n",
    "textcorpus_telephony['lemma'] = lemmatization(textcorpus_telephony['words'])\n",
    "\n",
    "textcorpus_shipment.purchase_name = textcorpus_shipment.purchase_name.apply(lowercase)\n",
    "textcorpus_shipment['words'] = textcorpus_shipment.purchase_name.apply(tokenization)\n",
    "textcorpus_shipment['lemma'] = lemmatization(textcorpus_shipment['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАЗБИВКА НАБОРОВ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбивка исходного файла на 2 части: обучающую и тестовую выборки в соотношении 7:3\n",
    "textcorpus_profile_train, textcorpus_profile_test, labels_profile_train, labels_profile_test = model_selection.train_test_split(textcorpus_profile.words, textcorpus_profile.label, test_size = 0.3)\n",
    "textcorpus_mobile_train, textcorpus_mobile_test, labels_mobile_train, labels_mobile_test = model_selection.train_test_split(textcorpus_mobile.words, textcorpus_mobile.label, test_size = 0.3)\n",
    "textcorpus_link_train, textcorpus_link_test, labels_link_train, labels_link_test = model_selection.train_test_split(textcorpus_link.words, textcorpus_link.label, test_size = 0.3)\n",
    "textcorpus_internet_train, textcorpus_internet_test, labels_internet_train, labels_internet_test = model_selection.train_test_split(textcorpus_internet.words, textcorpus_internet.label, test_size = 0.3)\n",
    "textcorpus_telephony_train, textcorpus_telephony_test, labels_telephony_train, labels_telephony_test = model_selection.train_test_split(textcorpus_telephony.words, textcorpus_telephony.label, test_size = 0.3)\n",
    "textcorpus_shipment_train, textcorpus_shipment_test, labels_shipment_train, labels_shipment_test = model_selection.train_test_split(textcorpus_shipment.words, textcorpus_shipment.label, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ФУНКЦИИ ДЛЯ СОЗДАНИЯ СЛОВАРЕЙ И ИХ ПРИМЕНЕНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 101909,
     "status": "ok",
     "timestamp": 1602084203608,
     "user": {
      "displayName": "Piton Piton",
      "photoUrl": "",
      "userId": "17891623094940807329"
     },
     "user_tz": -180
    },
    "id": "AzowfS_kku-p"
   },
   "outputs": [],
   "source": [
    "# функция для создания неуникального словаря\n",
    "def non_unique_dictionary_profile(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def non_unique_dictionary_mobile(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def non_unique_dictionary_link(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def non_unique_dictionary_internet(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def non_unique_dictionary_telephony(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def non_unique_dictionary_shipment(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "# функция для создания уникального словаря\n",
    "def unique_dictionary_profile(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def unique_dictionary_mobile(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def unique_dictionary_link(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def unique_dictionary_internet(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def unique_dictionary_telephony(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "def unique_dictionary_shipment(textcorpus_words):\n",
    "    words = []\n",
    "    for i in textcorpus_words.index: \n",
    "        for j in range(len(textcorpus_words[i])):\n",
    "            if textcorpus_words[i][j] not in words:\n",
    "                words.append(textcorpus_words[i][j])\n",
    "    return words\n",
    "\n",
    "# функция для выявления низкочастотных слов\n",
    "def low_frequency_profile(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_profile:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "def low_frequency_mobile(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_mobile:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "def low_frequency_link(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_link:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "def low_frequency_internet(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_internet:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "def low_frequency_telephony(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_telephony:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "def low_frequency_shipment(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_shipment:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val < 10}\n",
    "    return dictionary\n",
    "\n",
    "# функция для выявления высокочастотных слов\n",
    "def high_frequency_profile(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_profile:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "def high_frequency_mobile(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_mobile:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "def high_frequency_link(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_link:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "def high_frequency_internet(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_internet:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "def high_frequency_telephony(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_telephony:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "def high_frequency_shipment(dictionary):\n",
    "    dictionary = Counter()\n",
    "    for i in non_unique_dictionary_shipment:\n",
    "        dictionary[i] += 1\n",
    "    dictionary = {key: val for key, val in dictionary.items() if val > 10}\n",
    "    return dictionary\n",
    "\n",
    "# функция для создания оптимизированного словаря\n",
    "def optimized_dictionary_profile(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "def optimized_dictionary_mobile(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "def optimized_dictionary_link(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "def optimized_dictionary_internet(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "def optimized_dictionary_telephony(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "def optimized_dictionary_shipment(high_frequency):\n",
    "    optimized_dictionary = [i for i in high_frequency.keys()]\n",
    "    return optimized_dictionary\n",
    "\n",
    "# функция для создания мешка слов\n",
    "def bag_of_words(textcorpus_words, dictionary):\n",
    "    matrix = np.zeros((len(textcorpus_words), len(dictionary)))\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in textcorpus_words[textcorpus_words.index[i]]:\n",
    "            if j in dictionary:\n",
    "                matrix[i][dictionary.index(j)]+=1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 106105,
     "status": "ok",
     "timestamp": 1602084207808,
     "user": {
      "displayName": "Piton Piton",
      "photoUrl": "",
      "userId": "17891623094940807329"
     },
     "user_tz": -180
    },
    "id": "qkieqQUYku-u"
   },
   "outputs": [],
   "source": [
    "# для профильности услуг\n",
    "unique_dictionary_profile = unique_dictionary_profile(textcorpus_profile_train)\n",
    "non_unique_dictionary_profile = non_unique_dictionary_profile(textcorpus_profile_train)\n",
    "low_frequency_profile = low_frequency_profile(non_unique_dictionary_profile)\n",
    "high_frequency_profile = high_frequency_profile(non_unique_dictionary_profile)\n",
    "optimized_dictionary_profile = optimized_dictionary_profile(high_frequency_profile)\n",
    "# создание обучающего и тестового мешка слов\n",
    "train_bag_of_words_profile = bag_of_words(textcorpus_profile_train, optimized_dictionary_profile)\n",
    "test_bag_of_words_profile = bag_of_words(textcorpus_profile_test, optimized_dictionary_profile)\n",
    "\n",
    "# для мобильной связи\n",
    "unique_dictionary_mobile = unique_dictionary_mobile(textcorpus_mobile_train)\n",
    "non_unique_dictionary_mobile = non_unique_dictionary_mobile(textcorpus_mobile_train)\n",
    "low_frequency_mobile = low_frequency_mobile(non_unique_dictionary_mobile)\n",
    "high_frequency_mobile = high_frequency_mobile(non_unique_dictionary_mobile)\n",
    "optimized_dictionary_mobile = optimized_dictionary_mobile(high_frequency_mobile)\n",
    "# создание обучающего и тестового мешка слов\n",
    "train_bag_of_words_mobile = bag_of_words(textcorpus_mobile_train, optimized_dictionary_mobile)\n",
    "test_bag_of_words_mobile = bag_of_words(textcorpus_mobile_test, optimized_dictionary_mobile)\n",
    "\n",
    "# для каналов связи\n",
    "unique_dictionary_link = unique_dictionary_link(textcorpus_link_train)\n",
    "non_unique_dictionary_link = non_unique_dictionary_link(textcorpus_link_train)\n",
    "low_frequency_link = low_frequency_link(non_unique_dictionary_link)\n",
    "high_frequency_link = high_frequency_link(non_unique_dictionary_link)\n",
    "optimized_dictionary_link = optimized_dictionary_link(high_frequency_link)\n",
    "# создание обучающего и тестового мешка слов\n",
    "train_bag_of_words_link = bag_of_words(textcorpus_link_train, optimized_dictionary_link)\n",
    "test_bag_of_words_link = bag_of_words(textcorpus_link_test, optimized_dictionary_link)\n",
    "\n",
    "# для интернета\n",
    "unique_dictionary_internet = unique_dictionary_internet(textcorpus_internet_train)\n",
    "non_unique_dictionary_internet = non_unique_dictionary_internet(textcorpus_internet_train)\n",
    "low_frequency_internet = low_frequency_internet(non_unique_dictionary_internet)\n",
    "high_frequency_internet = high_frequency_internet(non_unique_dictionary_internet)\n",
    "optimized_dictionary_internet = optimized_dictionary_internet(high_frequency_internet)\n",
    "# создание обучающего и тестового мешка слов\n",
    "train_bag_of_words_internet = bag_of_words(textcorpus_internet_train, optimized_dictionary_internet)\n",
    "test_bag_of_words_internet = bag_of_words(textcorpus_internet_test, optimized_dictionary_internet)\n",
    "\n",
    "# для телефонии\n",
    "unique_dictionary_telephony = unique_dictionary_telephony(textcorpus_telephony_train)\n",
    "non_unique_dictionary_telephony = non_unique_dictionary_telephony(textcorpus_telephony_train)\n",
    "low_frequency_telephony = low_frequency_telephony(non_unique_dictionary_telephony)\n",
    "high_frequency_telephony = high_frequency_telephony(non_unique_dictionary_telephony)\n",
    "optimized_dictionary_telephony = optimized_dictionary_telephony(high_frequency_telephony)\n",
    "\n",
    "# для поставки\n",
    "unique_dictionary_shipment = unique_dictionary_shipment(textcorpus_shipment_train)\n",
    "non_unique_dictionary_shipment = non_unique_dictionary_shipment(textcorpus_shipment_train)\n",
    "low_frequency_shipment = low_frequency_shipment(non_unique_dictionary_shipment)\n",
    "high_frequency_shipment = high_frequency_shipment(non_unique_dictionary_shipment)\n",
    "optimized_dictionary_shipment = optimized_dictionary_shipment(high_frequency_shipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание обучающего мешка слов\n",
    "train_bag_of_words_profile = bag_of_words(textcorpus_profile_train, optimized_dictionary_profile)\n",
    "train_bag_of_words_mobile = bag_of_words(textcorpus_mobile_train, optimized_dictionary_mobile)\n",
    "train_bag_of_words_link = bag_of_words(textcorpus_link_train, optimized_dictionary_link)\n",
    "train_bag_of_words_internet = bag_of_words(textcorpus_internet_train, optimized_dictionary_internet)\n",
    "train_bag_of_words_telephony = bag_of_words(textcorpus_telephony_train, optimized_dictionary_telephony)\n",
    "train_bag_of_words_shipment = bag_of_words(textcorpus_shipment_train, optimized_dictionary_shipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание тестового мешка слов\n",
    "test_bag_of_words_profile = bag_of_words(textcorpus_profile_test, optimized_dictionary_profile)\n",
    "test_bag_of_words_mobile = bag_of_words(textcorpus_mobile_test, optimized_dictionary_mobile)\n",
    "test_bag_of_words_link = bag_of_words(textcorpus_link_test, optimized_dictionary_link)\n",
    "test_bag_of_words_internet = bag_of_words(textcorpus_internet_test, optimized_dictionary_internet)\n",
    "test_bag_of_words_telephony = bag_of_words(textcorpus_telephony_test, optimized_dictionary_telephony)\n",
    "test_bag_of_words_shipment = bag_of_words(textcorpus_shipment_test, optimized_dictionary_shipment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ФУНКЦИИ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ И ИХ ПРИМЕНЕНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для профильности услуг\n",
    "def logit_regression_profile(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_profile\n",
    "    global pred_logit_test_profile\n",
    "    global est_logit_profile\n",
    "    est_logit_profile = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_profile = est_logit_profile.predict(textcorpus_train)\n",
    "    pred_logit_test_profile = est_logit_profile.predict(textcorpus_test)\n",
    "    \n",
    "# для мобильной связи\n",
    "def logit_regression_mobile(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_mobile\n",
    "    global pred_logit_test_mobile\n",
    "    global est_logit_mobile\n",
    "    est_logit_mobile = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_mobile = est_logit_mobile.predict(textcorpus_train)\n",
    "    pred_logit_test_mobile = est_logit_mobile.predict(textcorpus_test)\n",
    "    \n",
    "# для каналов связи\n",
    "def logit_regression_link(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_link\n",
    "    global pred_logit_test_link\n",
    "    global est_logit_link\n",
    "    est_logit_link = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_link = est_logit_link.predict(textcorpus_train)\n",
    "    pred_logit_test_link = est_logit_link.predict(textcorpus_test)\n",
    "\n",
    "# для интернета\n",
    "def logit_regression_internet(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_internet\n",
    "    global pred_logit_test_internet\n",
    "    global est_logit_internet\n",
    "    est_logit_internet = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_internet = est_logit_internet.predict(textcorpus_train)\n",
    "    pred_logit_test_internet = est_logit_internet.predict(textcorpus_test)\n",
    "    \n",
    "# для телефонии\n",
    "def logit_regression_telephony(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_telephony\n",
    "    global pred_logit_test_telephony\n",
    "    global est_logit_telephony\n",
    "    est_logit_telephony = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_telephony = est_logit_telephony.predict(textcorpus_train)\n",
    "    pred_logit_test_telephony = est_logit_telephony.predict(textcorpus_test)\n",
    "    \n",
    "# для поставки\n",
    "def logit_regression_shipment(textcorpus_train, labels_train, textcorpus_test, labels_test):\n",
    "    global pred_logit_train_shipment\n",
    "    global pred_logit_test_shipment\n",
    "    global est_logit_shipment\n",
    "    est_logit_shipment = LogisticRegression().fit(textcorpus_train, labels_train)\n",
    "    pred_logit_train_shipment = est_logit_shipment.predict(textcorpus_train)\n",
    "    pred_logit_test_shipment = est_logit_shipment.predict(textcorpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108038,
     "status": "ok",
     "timestamp": 1602084209749,
     "user": {
      "displayName": "Piton Piton",
      "photoUrl": "",
      "userId": "17891623094940807329"
     },
     "user_tz": -180
    },
    "id": "1Z5b52fEku-3",
    "outputId": "baf903ee-c31a-48be-f227-78f1854fed91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# для профильности услуг\n",
    "logit_regression_profile = logit_regression_profile(\n",
    "    train_bag_of_words_profile, labels_profile_train, test_bag_of_words_profile, labels_profile_test)\n",
    "\n",
    "# для мобильной связи\n",
    "logit_regression_mobile = logit_regression_mobile(\n",
    "    train_bag_of_words_mobile, labels_mobile_train, test_bag_of_words_mobile, labels_mobile_test)\n",
    "\n",
    "# для каналов связи\n",
    "logit_regression_link = logit_regression_link(\n",
    "    train_bag_of_words_link, labels_link_train, test_bag_of_words_link, labels_link_test)\n",
    "\n",
    "# для интернета\n",
    "logit_regression_internet = logit_regression_internet(\n",
    "    train_bag_of_words_internet, labels_internet_train, test_bag_of_words_internet, labels_internet_test)\n",
    "\n",
    "# для телефонии\n",
    "logit_regression_telephony = logit_regression_telephony(\n",
    "    train_bag_of_words_telephony, labels_telephony_train, test_bag_of_words_telephony, labels_telephony_test)\n",
    "\n",
    "# для поставки\n",
    "logit_regression_shipment = logit_regression_shipment(\n",
    "    train_bag_of_words_shipment, labels_shipment_train, test_bag_of_words_shipment, labels_shipment_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫГРУЗКА ДАННЫХ ИЗ ЦХД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = '10.42.100.64'\n",
    "port = '5432'\n",
    "user = 'nikolay.kozhevnikov' # необходимо ввести собственный логин от учетной записи\n",
    "database = 'edw_prod'\n",
    "pwd = '%z22u5#K5F' #необходимо ввести собственный пароль от учетной записи\n",
    "\n",
    "str_con = 'postgresql://'+user+':'+pwd+'@'+host+':'+port+'/'+database\n",
    "connection = create_engine(str_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_select = \"SELECT cast(tenderid as Integer), purchase_name, tender_created_date \"\n",
    "# query_from = \"FROM edw_dm_b2b.tfct_tender_stream \"\n",
    "# query_where = \"WHERE tender_created_date BETWEEN '10.01.2021' AND '12.30.2021' AND period = date_trunc('YEAR', current_date) AND winner_order = 1 AND tender_status IN ('Выиграна', 'Проиграна', 'Отказ от участия', 'Единственный поставщик', 'Заявка отклонена', 'Заявка подана', 'Малая закупка', 'Отменена', 'Дублированная', 'Ответили на мониторинг', 'Ошибочная закупка', 'Игнорирована', 'Просрочена')\"\n",
    "# query_where = \"WHERE applicationenddate BETWEEN '11.01.2020' AND '12.31.2020' AND period = date_trunc('YEAR', current_date) AND winner_order = 1\"\n",
    "# query = query_select + query_from + query_where\n",
    "# textcorpus_prod = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_select = \"SELECT cast(tenderid as Integer), purchase_name, tender_created_date \"\n",
    "query_from = \"FROM edw_dm_b2b.tfct_tender_stream \"\n",
    "# query_where = \"WHERE tender_created_date BETWEEN '08.01.2021' AND '12.31.2021' AND period = date_trunc('YEAR', current_date) AND winner_order = 1 AND tender_status IN ('Выиграна', 'Проиграна', 'Отказ от участия', 'Единственный поставщик', 'Заявка отклонена', 'Заявка подана', 'Малая закупка', 'Отменена', 'Дублированная', 'Ответили на мониторинг', 'Ошибочная закупка', 'Игнорирована', 'Просрочена', 'Новая', 'В работе', 'Закупка \\\"Ростелеком\\\"', 'Подготовка заявки')\"\n",
    "query_where = \"WHERE tender_created_date BETWEEN '04.01.2022' AND '06.30.2022' AND period = date_trunc('YEAR', current_date) AND winner_order = 1\"\n",
    "query = query_select + query_from + query_where\n",
    "textcorpus_prod = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_select = \"SELECT cast(tenderid as Integer), purchase_name, tender_created_date \"\n",
    "# query_from = \"FROM edw_dm_b2b.tfct_tender_stream \"\n",
    "# query_where = \"WHERE tender_created_date BETWEEN '10.01.2021' AND '12.30.2021' AND period = date_trunc('YEAR', current_date) AND winner_order = 1\"\n",
    "# query_where = \"WHERE applicationenddate BETWEEN '11.01.2020' AND '12.31.2020' AND period = date_trunc('YEAR', current_date) AND winner_order = 1\"\n",
    "# query = query_select + query_from + query_where\n",
    "# textcorpus_prod1 = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-28 09:41:06.733507 ///// 2022-04-26 19:41:06.733548\n"
     ]
    }
   ],
   "source": [
    "end_date = datetime.today()\n",
    "start_date = datetime.today() - timedelta(days=1, hours=14)\n",
    "textcorpus_prod =  textcorpus_prod[(textcorpus_prod['tender_created_date'] > start_date) & (textcorpus_prod['tender_created_date'] <= end_date)]\n",
    "print(end_date, '/////', start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('dev_kozhevnikov/model/df_bd_test.xlsx') as writer:\n",
    "    textcorpus_prod.to_excel(writer, sheet_name='sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxsB5oRZku_A"
   },
   "source": [
    "## ПРИМЕНЕНИЕ МОДЕЛИ МАШИННОГО ОБУЧЕНИЯ НА ДАННЫХ ИЗ ЦХД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcorpus_prod = pd.DataFrame() # создание пустого датафрейма|\n",
    "textcorpus_prod = pd.read_excel('dev_kozhevnikov/model/textcorpus_prod.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textcorpus_prod из ЦХД\n",
    "textcorpus_prod['purchase_name'] = textcorpus_prod.purchase_name.apply(lowercase)\n",
    "textcorpus_prod['words'] = textcorpus_prod.purchase_name.apply(tokenization)\n",
    "textcorpus_prod.reset_index(inplace = True)\n",
    "textcorpus_prod['lemma'] = lemmatization(textcorpus_prod['words'])\n",
    "matrix_prod_profile = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_profile)\n",
    "matrix_prod_mobile = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_mobile)\n",
    "matrix_prod_link = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_link)\n",
    "matrix_prod_internet = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_internet)\n",
    "matrix_prod_telephony = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_telephony)\n",
    "matrix_prod_shipment = bag_of_words(textcorpus_prod.lemma, optimized_dictionary_shipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logit_prod_profile = est_logit_profile.predict(matrix_prod_profile)\n",
    "pred_logit_prod_profile_df = pd.DataFrame(pred_logit_prod_profile)\n",
    "textcorpus_prod['label_profile'] = pred_logit_prod_profile_df\n",
    "\n",
    "pred_logit_prod_mobile = est_logit_mobile.predict(matrix_prod_mobile)\n",
    "pred_logit_prod_mobile_df = pd.DataFrame(pred_logit_prod_mobile)\n",
    "textcorpus_prod['label_mobile'] = pred_logit_prod_mobile_df\n",
    "\n",
    "pred_logit_prod_link = est_logit_link.predict(matrix_prod_link)\n",
    "pred_logit_prod_link_df = pd.DataFrame(pred_logit_prod_link)\n",
    "textcorpus_prod['label_link'] = pred_logit_prod_link_df\n",
    "\n",
    "pred_logit_prod_internet = est_logit_internet.predict(matrix_prod_internet)\n",
    "pred_logit_prod_internet_df = pd.DataFrame(pred_logit_prod_internet)\n",
    "textcorpus_prod['label_internet'] = pred_logit_prod_internet_df\n",
    "\n",
    "pred_logit_prod_telephony = est_logit_telephony.predict(matrix_prod_telephony)\n",
    "pred_logit_prod_telephony_df = pd.DataFrame(pred_logit_prod_telephony)\n",
    "textcorpus_prod['label_telephony'] = pred_logit_prod_telephony_df\n",
    "\n",
    "pred_logit_prod_shipment = est_logit_shipment.predict(matrix_prod_shipment)\n",
    "pred_logit_prod_shipment_df = pd.DataFrame(pred_logit_prod_shipment)\n",
    "textcorpus_prod['label_shipment'] = pred_logit_prod_shipment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcorpus_prod = textcorpus_prod[['tenderid', 'label_profile', 'label_mobile', 'label_link', 'label_internet', 'label_telephony', 'label_shipment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3934, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcorpus_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выгрузка результатов\n",
    "with pd.ExcelWriter('dev_kozhevnikov/model/df_bd.xlsx') as writer:\n",
    "    textcorpus_prod.to_excel(writer, sheet_name='sheet1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАГРУЗКА ДАННЫХ В GREENPLUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# не менять if_exists = append!!!!!!!!!!!\n",
    "\n",
    "textcorpus_prod.to_sql('tender_label_new_2', con=connection, schema='public', if_exists='append', index=False)\n",
    "#df = pd.read_sql(\"SELECT * FROM public.tender_label_new_2\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ml_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
